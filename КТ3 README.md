Реализован Python-скрипт, который:

Загружает CSV-файл World Important Dates.csv с локального диска.

Производит предобработку данных:

удаляет пропуски (dropna()),

убирает дубликаты (drop_duplicates()).

Конвертирует очищенные данные в формат Parquet.

С помощью docker cp копирует файл внутрь Hadoop-контейнера.

Через hdfs dfs -put загружает его в HDFS.

Выполняет hdfs dfs -ls, чтобы проверить успешную выгрузку.