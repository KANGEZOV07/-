{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e3539",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "input_file_path = 'C:\\\\Users\\\\User\\\\Desktop\\\\docker-hadoop\\\\World Important Dates.csv'\n",
    "output_file_path = 'C:\\\\Users\\\\User\\\\Desktop\\\\docker-hadoop\\\\out_data.parquet'\n",
    "hdfs_path = '/user/out_data.parquet'\n",
    "master_container_id = '53f1026cb573e407a6a0ec2fd7156ea41047d19f237967d6327b60fce5088b81'\n",
    "\n",
    "df = pd.read_csv(input_file_path, encoding='utf-8')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.to_parquet(output_file_path, index=False)\n",
    "docker_cp_command = f'docker cp {output_file_path} {master_container_id}:/tmp/out_data.parquet'\n",
    "subprocess.run(docker_cp_command, shell=True)\n",
    "hdfs_command = f'docker exec {master_container_id} hdfs dfs -put /tmp/out_data.parquet {hdfs_path}'\n",
    "subprocess.run(hdfs_command, shell=True)\n",
    "check_command = f'docker exec {master_container_id} hdfs dfs -ls {hdfs_path}'\n",
    "result = subprocess.run(check_command, shell=True, capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
